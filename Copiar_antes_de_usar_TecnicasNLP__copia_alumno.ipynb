{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copiar_antes_de_usar_TecnicasNLP__copia_alumno.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GGQMv38J7w0l"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseobrien/UCM-Data-Science/blob/main/Copiar_antes_de_usar_TecnicasNLP__copia_alumno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_RKycgu-3GD"
      },
      "source": [
        "# Técnicas Básicas de NLP en el Text Mining\n",
        "\n",
        "En el Text Mining y el NLP se utilizan librerías tradicionales de Data Mining, como scikit-learn o Tensorflow, pero también librerías específicas para trabajar con texto. \n",
        "\n",
        "Existen multitud de librerías diseñadas para preprocesar textos, transformar textos en vectores u orientadas a poner modelos de TM en producción. En este notebook introduciremos 2 de ellas, viendo algunas de sus funcionalides y como aplicar diferentes técnicas básicas de NLP utilizandolas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkKFmU6Z_Nuv"
      },
      "source": [
        "En primer lugar, instalaremos os las librerías de programación que utilizaremos en este notebook:\n",
        "- [**NLTK**](https://www.nltk.org//): NLTK es una de las librerías principales para trabajar con textos libres que fue creada por la Universidad de Pennsylvania en el año 2001. Aunque su uso principal ha estado unido  a entornos de investigación y educación, las facilidades en su uso y sus características la convierten en una de las librerías con un mayor número de recursos de aprendizaje como libros, foros o tutoriales. Contiene una gran cantidad de conjuntos de datos típicos para el aprendizaje de NLP y es muy utilizada en tareas para el preprocesado de texto antes de introducirlo en algoritmos de Inteligencia Artificial.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbD6Enj5_M_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29d54a0-6fc8-4dbd-ba45-4e766ef6ac88"
      },
      "source": [
        "# Instalamos nltk\n",
        "!pip install nltk\n",
        "# Importamos\n",
        "import nltk\n",
        "# Complementos de la librería necesarios para su funcionamiento.\n",
        "# Todas las opciones aquí https://www.nltk.org/nltk_data/ \n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [**Spacy**](https://spacy.io/): A diferencia de NLTK, que surgió y ha sido diseñada para ser utilizada en entornos de investigación, Spacy se centra en proporcionar herramientas para poder incorporar sistemas de Text Mining en producción por facilidad. De hecho, su fácil interconexión con otras librerías del mundo de la ciencia de datos, junto a la incorporación de modelos pre-entrenados con técnicas de Deep Learning y su facilidad para trabajar con múltiples lenguajes de programación, la han convertido en una de las librarías más usadas, si no la que más, en la actualidad. \n",
        "\n",
        "    Descargamos la librería y los modelos pre-entretados *en_core_web_sm* y *es_core_web_sm*, modelos de DNN entrenados con noticias, blogs y comentarios en inglés y español respectivamente.\n"
      ],
      "metadata": {
        "id": "DHQmVOgz12bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos textacy\n",
        "!pip install textacy\n",
        "# Instalamos spacy y uno de sus modelos\n",
        "!pip install spacy\n",
        "# Descargamos modelos pre-entrenados de spacy.\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "# Descargamos datos del repositorio de github\n",
        "!wget \"https://github.com/luisgasco/ntic_master_datos/raw/main/datasets/news_summary.csv\""
      ],
      "metadata": {
        "id": "tZHsQNR21c13",
        "outputId": "0cebcb2b-8a34-4e85-cc1b-a4642ad7da67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Downloading textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 200 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Collecting spacy>=3.0.0\n",
            "  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 43.3 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 30.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.7)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.9)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1236702 sha256=2b795134f1e3009f31256bdbde2027a5c91b06862540a6c727d6c9f75e3ee5c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73988 sha256=696f4022d30b6ebb1db39ba3c07ff946ed6c0fa17ce5083ac47b0eb6df3d2136\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 textacy-0.11.0 thinc-8.0.16 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.16)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.16)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Collecting es-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.3.0/es_core_news_sm-3.3.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (8.0.16)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "--2022-05-22 20:11:55--  https://github.com/luisgasco/ntic_master_datos/raw/main/datasets/news_summary.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/luisgasco/ntic_master_datos/main/datasets/news_summary.csv [following]\n",
            "--2022-05-22 20:11:55--  https://raw.githubusercontent.com/luisgasco/ntic_master_datos/main/datasets/news_summary.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11896415 (11M) [text/plain]\n",
            "Saving to: ‘news_summary.csv’\n",
            "\n",
            "news_summary.csv    100%[===================>]  11.34M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-05-22 20:11:56 (114 MB/s) - ‘news_summary.csv’ saved [11896415/11896415]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías tpipicas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OWl6P7LC1fk6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSPqbcfADMU"
      },
      "source": [
        "\n",
        "## Corpus y corpora\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPOvW4j6J2k9"
      },
      "source": [
        "Todo proceso de análisis textual comienza con un dataset de documentos textuales, que generalmente se llama **corpus** o *corpora* cuando tratamos con varios datasets. El corpus generalmente está compuesto de texto bruto con algunos metadatos asociados, aunque esto no tiene por qué ser así. \n",
        "\n",
        "En este Notebook vamos a trabajar con un corpus de noticias distribuido en la plataforma Kaggle llamado [*News summary*](https://www.kaggle.com/sunnysai12345/news-summary). Este corpus está distribuido en formato *csv*, sin embargo es normal encontrar corpus con el formato *tsv*, o disponer de corpus almacenados en base de datos como MongoDB.\n",
        "\n",
        "En primer lugar lo leeremos de la ruta donde se ha descargado `/content/news_summary.csv`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63vDxqL1_NIQ",
        "outputId": "93ad66c2-051f-4425-c719-0379e95efb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "news_summary = pd.read_csv('../content/news_summary.csv', encoding='latin-1')\n",
        "news_summary.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           author                  date  \\\n",
              "0    Chhavi Tyagi  03 Aug 2017,Thursday   \n",
              "1     Daisy Mowke  03 Aug 2017,Thursday   \n",
              "2  Arshiya Chopra  03 Aug 2017,Thursday   \n",
              "\n",
              "                                           headlines  \\\n",
              "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
              "1  Malaika slams user who trolled her for 'divorc...   \n",
              "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
              "\n",
              "                                           read_more  \\\n",
              "0  http://www.hindustantimes.com/india-news/raksh...   \n",
              "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
              "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
              "\n",
              "                                                text  \\\n",
              "0  The Administration of Union Territory Daman an...   \n",
              "1  Malaika Arora slammed an Instagram user who tr...   \n",
              "2  The Indira Gandhi Institute of Medical Science...   \n",
              "\n",
              "                                               ctext  \n",
              "0  The Daman and Diu administration on Wednesday ...  \n",
              "1  From her special numbers to TV?appearances, Bo...  \n",
              "2  The Indira Gandhi Institute of Medical Science...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0cef55d-1000-4d50-91b3-2e170166f17c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>headlines</th>\n",
              "      <th>read_more</th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chhavi Tyagi</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
              "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daisy Mowke</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
              "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arshiya Chopra</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
              "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0cef55d-1000-4d50-91b3-2e170166f17c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0cef55d-1000-4d50-91b3-2e170166f17c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0cef55d-1000-4d50-91b3-2e170166f17c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKCz2OkK7Dw"
      },
      "source": [
        "El dataset está compuesto por un conjunto de filas, que llamamos documentos. Cada documento tiene un conjunto de metadatos como el autor, la fecha, el titular de la noticia y la web de la noticia y el texto asociado a esta. \n",
        "\n",
        "Cada uno de los textos puede separarse en párrafos, frases y palabras según el tipo de documento y el tipo de análisis que se le vaya a aplicar. \n",
        "\n",
        "En este caso, al ser un ejercicio, únicamente vamos a trabajar con el texto de los documentos, correspondiente el campo \"text\", así que extraeremos y transformaremos esta columna en una lista para trabajar más comodos:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNunkfZiFbuT",
        "outputId": "8698f526-10cb-4931-a46d-497ba149b7e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transformar la columna \"text\" a una lista\n",
        "texto_noticias = news_summary[\"text\"].to_list()\n",
        "print(type(texto_noticias))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YjLBJyWaJx0"
      },
      "source": [
        "Vamos a mirar el número de noticias que contiene nuestro corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAOAowZpaIgr",
        "outputId": "40abad65-df99-42a2-eba6-3c67c8f233e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk import text\n",
        "print(\"El corpus news_summary contiene un total de {} documentos\".format(len(texto_noticias)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El corpus news_summary contiene un total de 4514 documentos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4qnmYM1AEOt"
      },
      "source": [
        "## Tokenización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CIwmkQzaYOD"
      },
      "source": [
        "El texto bruto está compuesto por una secuencia de caracteres. Antes de su análisis los textos son divididos en fragmentos más pequeños conocidos como tokens. Un token puede ser tanto una palabra, como un símbolo de puntuación, un número o un emoticono, en el caso de estar analizando datos de redes sociales.\n",
        "\n",
        "El proceso de división del texto en tokens se llama tokenización. Aquí se muestra el proceso tanto para la librería Spacy como para la librería NLTK para un único texto del corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Q35k2varmO"
      },
      "source": [
        "***NLTK***\n",
        "\n",
        "El tokenizador estándar de NLTK se llama word_tokenize. Podemos ver más información dentro de la web de documentación de NLTK (dentro del módulo word_tokenize [texto del enlace](https://www.nltk.org/api/nltk.tokenize.html))\n",
        "\n",
        "\n",
        "También podemos utilizar la línea de código `?libreria.modulo.funcion` para que nos aparezca la ayuda de la función en la parte derecha de la pantalla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRtb67v8jRis"
      },
      "source": [
        "?nltk.tokenize.word_tokenize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# Cogemos un subset de las 100 primeras noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]"
      ],
      "metadata": {
        "id": "57fBwpXHf1JD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4BYnwsAOMd",
        "outputId": "acc51f63-6ad6-4488-d09c-47a4df18bac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Segmentar las frases de la noticia 5 (indice 4)\n",
        "sentences = sent_tokenize(subset_noticias[4])\n",
        "for num,sentence in enumerate(sentences):\n",
        "    print('La oración número {} es: \\n {}'.format(num, sentence))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración número 0 es: \n",
            " Hotels in Maharashtra will train their staff to spot signs of sex trafficking, including frequent requests for bed linen changes and 'Do not disturb' signs left on room doors for days.\n",
            "La oración número 1 es: \n",
            " A mobile phone app called Rescue Me, which will allow staff to alert police of suspicious behaviour, will be developed.\n",
            "La oración número 2 es: \n",
            " The initiative has been backed by the Maharashtra government.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb9frcvnlu88"
      },
      "source": [
        "Podemos segmentar todos los tokens de un documento de forma global."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzXvGAfylvO1",
        "outputId": "e48bc106-e38b-4db5-aeb5-b39af1adf003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Segmentar los tokens de la noticia 5 (indice 4)\n",
        "tokens = word_tokenize(subset_noticias[4])\n",
        "for num,token in enumerate(tokens):\n",
        "    print('El token {} es {} '.format(num,token))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El token 0 es Hotels \n",
            "El token 1 es in \n",
            "El token 2 es Maharashtra \n",
            "El token 3 es will \n",
            "El token 4 es train \n",
            "El token 5 es their \n",
            "El token 6 es staff \n",
            "El token 7 es to \n",
            "El token 8 es spot \n",
            "El token 9 es signs \n",
            "El token 10 es of \n",
            "El token 11 es sex \n",
            "El token 12 es trafficking \n",
            "El token 13 es , \n",
            "El token 14 es including \n",
            "El token 15 es frequent \n",
            "El token 16 es requests \n",
            "El token 17 es for \n",
            "El token 18 es bed \n",
            "El token 19 es linen \n",
            "El token 20 es changes \n",
            "El token 21 es and \n",
            "El token 22 es 'Do \n",
            "El token 23 es not \n",
            "El token 24 es disturb \n",
            "El token 25 es ' \n",
            "El token 26 es signs \n",
            "El token 27 es left \n",
            "El token 28 es on \n",
            "El token 29 es room \n",
            "El token 30 es doors \n",
            "El token 31 es for \n",
            "El token 32 es days \n",
            "El token 33 es . \n",
            "El token 34 es A \n",
            "El token 35 es mobile \n",
            "El token 36 es phone \n",
            "El token 37 es app \n",
            "El token 38 es called \n",
            "El token 39 es Rescue \n",
            "El token 40 es Me \n",
            "El token 41 es , \n",
            "El token 42 es which \n",
            "El token 43 es will \n",
            "El token 44 es allow \n",
            "El token 45 es staff \n",
            "El token 46 es to \n",
            "El token 47 es alert \n",
            "El token 48 es police \n",
            "El token 49 es of \n",
            "El token 50 es suspicious \n",
            "El token 51 es behaviour \n",
            "El token 52 es , \n",
            "El token 53 es will \n",
            "El token 54 es be \n",
            "El token 55 es developed \n",
            "El token 56 es . \n",
            "El token 57 es The \n",
            "El token 58 es initiative \n",
            "El token 59 es has \n",
            "El token 60 es been \n",
            "El token 61 es backed \n",
            "El token 62 es by \n",
            "El token 63 es the \n",
            "El token 64 es Maharashtra \n",
            "El token 65 es government \n",
            "El token 66 es . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ9DgBr0l2Z1"
      },
      "source": [
        "Pero también se puede segmentar los tokens de cada una de las frases separadamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSqTIr8Al2qL",
        "outputId": "5af8f8a6-ea6a-45b2-ec12-db2b3ef7cd2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Segmentar las frases de la noticia 5 (indice 4)\n",
        "sentences = sent_tokenize(subset_noticias[4])\n",
        "for num_sen, sentence in enumerate(sentences):\n",
        "  # Segmentar los tokens de las frases de la noticia 5 (indice 4)\n",
        "  tokens = word_tokenize(sentence)\n",
        "  for num_token, token in enumerate(tokens):\n",
        "    print(\"El token {} de la frase {} es: {}\".format(num_token, num_sen,token))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El token 0 de la frase 0 es: Hotels\n",
            "El token 1 de la frase 0 es: in\n",
            "El token 2 de la frase 0 es: Maharashtra\n",
            "El token 3 de la frase 0 es: will\n",
            "El token 4 de la frase 0 es: train\n",
            "El token 5 de la frase 0 es: their\n",
            "El token 6 de la frase 0 es: staff\n",
            "El token 7 de la frase 0 es: to\n",
            "El token 8 de la frase 0 es: spot\n",
            "El token 9 de la frase 0 es: signs\n",
            "El token 10 de la frase 0 es: of\n",
            "El token 11 de la frase 0 es: sex\n",
            "El token 12 de la frase 0 es: trafficking\n",
            "El token 13 de la frase 0 es: ,\n",
            "El token 14 de la frase 0 es: including\n",
            "El token 15 de la frase 0 es: frequent\n",
            "El token 16 de la frase 0 es: requests\n",
            "El token 17 de la frase 0 es: for\n",
            "El token 18 de la frase 0 es: bed\n",
            "El token 19 de la frase 0 es: linen\n",
            "El token 20 de la frase 0 es: changes\n",
            "El token 21 de la frase 0 es: and\n",
            "El token 22 de la frase 0 es: 'Do\n",
            "El token 23 de la frase 0 es: not\n",
            "El token 24 de la frase 0 es: disturb\n",
            "El token 25 de la frase 0 es: '\n",
            "El token 26 de la frase 0 es: signs\n",
            "El token 27 de la frase 0 es: left\n",
            "El token 28 de la frase 0 es: on\n",
            "El token 29 de la frase 0 es: room\n",
            "El token 30 de la frase 0 es: doors\n",
            "El token 31 de la frase 0 es: for\n",
            "El token 32 de la frase 0 es: days\n",
            "El token 33 de la frase 0 es: .\n",
            "El token 0 de la frase 1 es: A\n",
            "El token 1 de la frase 1 es: mobile\n",
            "El token 2 de la frase 1 es: phone\n",
            "El token 3 de la frase 1 es: app\n",
            "El token 4 de la frase 1 es: called\n",
            "El token 5 de la frase 1 es: Rescue\n",
            "El token 6 de la frase 1 es: Me\n",
            "El token 7 de la frase 1 es: ,\n",
            "El token 8 de la frase 1 es: which\n",
            "El token 9 de la frase 1 es: will\n",
            "El token 10 de la frase 1 es: allow\n",
            "El token 11 de la frase 1 es: staff\n",
            "El token 12 de la frase 1 es: to\n",
            "El token 13 de la frase 1 es: alert\n",
            "El token 14 de la frase 1 es: police\n",
            "El token 15 de la frase 1 es: of\n",
            "El token 16 de la frase 1 es: suspicious\n",
            "El token 17 de la frase 1 es: behaviour\n",
            "El token 18 de la frase 1 es: ,\n",
            "El token 19 de la frase 1 es: will\n",
            "El token 20 de la frase 1 es: be\n",
            "El token 21 de la frase 1 es: developed\n",
            "El token 22 de la frase 1 es: .\n",
            "El token 0 de la frase 2 es: The\n",
            "El token 1 de la frase 2 es: initiative\n",
            "El token 2 de la frase 2 es: has\n",
            "El token 3 de la frase 2 es: been\n",
            "El token 4 de la frase 2 es: backed\n",
            "El token 5 de la frase 2 es: by\n",
            "El token 6 de la frase 2 es: the\n",
            "El token 7 de la frase 2 es: Maharashtra\n",
            "El token 8 de la frase 2 es: government\n",
            "El token 9 de la frase 2 es: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-QhTx6RasMt"
      },
      "source": [
        "***Spacy***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxc32p8qmJDQ"
      },
      "source": [
        "En Spacy el funcionamiento es algo distinto:\n",
        "En primer lugar es necesario cargar un objeto spacy pre-entrenado proporcionado por los creadores de la librería (o por cualquier otro usuario que lo haya compartido). \n",
        "\n",
        "![Picture1.png](data:image/png;base64,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)\n",
        "Los modelos incorporados con Spacy se pueden encontrar en su[ web](https://spacy.io/usage/facts-figures#benchmarks). Estos objetos permiten procesar documentos completos y extraer información de ellos como los tokens, PoS, o lemmas.\n",
        "\n",
        "En primer lugar cargamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdyDrbomVUO"
      },
      "source": [
        "import spacy\n",
        "# Cargamos el modelo preentrenado con textos en inglés (\"en_core_web_sm\")\n",
        "nlp= spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp"
      ],
      "metadata": {
        "id": "kKYBAyemjPXa",
        "outputId": "b7c244b9-6f3f-4885-f21c-81275119fa47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f68848dc910>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrx9Xn0KnGyl"
      },
      "source": [
        "A continuación, vamos a coger el mismo subset de noticias y vamos a aplicar el objeto nlp creado anteriormente a cada uno de los documentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrM0ISjvmIZm",
        "outputId": "438ea417-8978-4a40-e4ec-8e9ed91449ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "# Obtener una lista de objetos de tipo spacy procesados por spacy\n",
        "documento = nlp(subset_noticias[0])\n",
        "type(documento)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos la lista de docuimentos procesados por el objeto nlp de spacy\n",
        "lista_documentos = [nlp(noticia) for noticia in subset_noticias]"
      ],
      "metadata": {
        "id": "XZ0is9STgSef"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONfvB5PS5E49",
        "outputId": "5c192eac-b01d-4458-b010-1ab3da6a23e3"
      },
      "source": [
        "type(lista_documentos[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMcf88yAnTLm"
      },
      "source": [
        "\n",
        "Esto ha transformado nuestros textos a objetos de tipo [`spacy.tokens.doc.Doc`](https://spacy.io/api/doc) que tiene una serie de atributos y métodos útiles para nuestro pipeline.\n",
        "\n",
        "Como hemos hecho antes, en primer lugar vamos a extraer las frases del documento 4.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quJmRuthoEXj",
        "outputId": "907e83bb-8bd5-471a-d399-75419823540b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Segmentamos el texto de la noticia 4 en oraciones:\n",
        "for num,sentence in enumerate(lista_documentos[4].sents):\n",
        "    print('La oración número {} es: \\n {}'.format(num, sentence))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración número 0 es: \n",
            " Hotels in Maharashtra will train their staff to spot signs of sex trafficking, including frequent requests for bed linen changes and 'Do not disturb' signs left on room doors for days.\n",
            "La oración número 1 es: \n",
            " A mobile phone app called Rescue Me, which will allow staff to alert police of suspicious behaviour, will be developed.\n",
            "La oración número 2 es: \n",
            " The initiative has been backed by the Maharashtra government.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dPa45oUoC3i"
      },
      "source": [
        "Vamos a mostrar los tokens de cada una de las frases.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzTqVstsasWD",
        "outputId": "f37bd598-f191-4ca5-d877-3cf01ae0bdea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Además también podemos dividir cada frase en tokens para la noticia 4:\n",
        "for num,sentence in enumerate(lista_documentos[4].sents):\n",
        "    print('La oración {} tiene {} tokens'.format(num, len(sentence)))\n",
        "    tokens=[word for word in sentence]\n",
        "    print(tokens)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración 0 tiene 35 tokens\n",
            "[Hotels, in, Maharashtra, will, train, their, staff, to, spot, signs, of, sex, trafficking, ,, including, frequent, requests, for, bed, linen, changes, and, ', Do, not, disturb, ', signs, left, on, room, doors, for, days, .]\n",
            "La oración 1 tiene 23 tokens\n",
            "[A, mobile, phone, app, called, Rescue, Me, ,, which, will, allow, staff, to, alert, police, of, suspicious, behaviour, ,, will, be, developed, .]\n",
            "La oración 2 tiene 10 tokens\n",
            "[The, initiative, has, been, backed, by, the, Maharashtra, government, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55HccBd5AOa3"
      },
      "source": [
        "## Unigramas, Bigramas y N-gramas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnyihnvCkRLr"
      },
      "source": [
        "En ocasiones, la información proporcionada por un token no es suficiente. \n",
        "\n",
        "Existen palabras que tienen relación con los términos previos y/o posteriores. Desde un punto de vista *naive*, la manera de conseguir el contexto de cada palabra es mediante los n-gramas.\n",
        "\n",
        "Los n-gramas son secuencias de n tokens consecutivos provenientes de un texto. La combinación de n-gramas puede proporcionar información sobre la temática de un texto. Generalmente se generan unigramas, que son iguales que los tokens del texto. Los Bigramas, que son combinaciones pareadas de tokens y los trigramas que son triadas de tokens "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxNQ1U9RmcRW"
      },
      "source": [
        "***NLTK***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4bnaR9uohDS"
      },
      "source": [
        "En NLTK los ngrams se consiguen a traves de un método dentro del módulo util de la librería."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds-zGjHlonG6"
      },
      "source": [
        "from nltk.util import ngrams\n",
        "?ngrams"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGNYwrv2pMMi"
      },
      "source": [
        "Vamos a generar una función para crear n-grams de distinto tamaño!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHD_1UeepMe0"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.util import ngrams\n",
        "# Función para extraer n-grams de una frase.\n",
        "def extraer_ngramas(datos, numero):\n",
        "    # Uso Utilizar la función ngrams para generar ngrams de textos \n",
        "    n_grams = ngrams(word_tokenize(datos), numero)\n",
        "    # Transformo el resultado en una lista\n",
        "    return [ ' '.join(grams) for grams in n_grams]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggqIn_ysprbE"
      },
      "source": [
        "Ahora vamos a generar un conjunto de bigramas, trigramas y 4-gramas de la noticia 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbpWISSPmcRh",
        "outputId": "534aa0b7-8ec2-43cb-edb7-ddf421a762e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "\n",
        "# Calculamos los bigramas, trigramas y 4 gramas de la noticia 4\n",
        "print(\"Unigramas: \", extraer_ngramas(subset_noticias[4],1))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigramas:  ['Hotels', 'in', 'Maharashtra', 'will', 'train', 'their', 'staff', 'to', 'spot', 'signs', 'of', 'sex', 'trafficking', ',', 'including', 'frequent', 'requests', 'for', 'bed', 'linen', 'changes', 'and', \"'Do\", 'not', 'disturb', \"'\", 'signs', 'left', 'on', 'room', 'doors', 'for', 'days', '.', 'A', 'mobile', 'phone', 'app', 'called', 'Rescue', 'Me', ',', 'which', 'will', 'allow', 'staff', 'to', 'alert', 'police', 'of', 'suspicious', 'behaviour', ',', 'will', 'be', 'developed', '.', 'The', 'initiative', 'has', 'been', 'backed', 'by', 'the', 'Maharashtra', 'government', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos los bigramas, trigramas y 4 gramas de la noticia 4\n",
        "print(\"Bigramas: \", extraer_ngramas(subset_noticias[4],2))\n",
        "print(\"Trigramas: \", extraer_ngramas(subset_noticias[4],3))\n",
        "print(\"4-gramas: \", extraer_ngramas(subset_noticias[4],4))\n",
        "\n"
      ],
      "metadata": {
        "id": "VUlSYDYHgbT9",
        "outputId": "c0e0178b-a790-41c0-e1ad-574b1488cbe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigramas:  ['Hotels in', 'in Maharashtra', 'Maharashtra will', 'will train', 'train their', 'their staff', 'staff to', 'to spot', 'spot signs', 'signs of', 'of sex', 'sex trafficking', 'trafficking ,', ', including', 'including frequent', 'frequent requests', 'requests for', 'for bed', 'bed linen', 'linen changes', 'changes and', \"and 'Do\", \"'Do not\", 'not disturb', \"disturb '\", \"' signs\", 'signs left', 'left on', 'on room', 'room doors', 'doors for', 'for days', 'days .', '. A', 'A mobile', 'mobile phone', 'phone app', 'app called', 'called Rescue', 'Rescue Me', 'Me ,', ', which', 'which will', 'will allow', 'allow staff', 'staff to', 'to alert', 'alert police', 'police of', 'of suspicious', 'suspicious behaviour', 'behaviour ,', ', will', 'will be', 'be developed', 'developed .', '. The', 'The initiative', 'initiative has', 'has been', 'been backed', 'backed by', 'by the', 'the Maharashtra', 'Maharashtra government', 'government .']\n",
            "Trigramas:  ['Hotels in Maharashtra', 'in Maharashtra will', 'Maharashtra will train', 'will train their', 'train their staff', 'their staff to', 'staff to spot', 'to spot signs', 'spot signs of', 'signs of sex', 'of sex trafficking', 'sex trafficking ,', 'trafficking , including', ', including frequent', 'including frequent requests', 'frequent requests for', 'requests for bed', 'for bed linen', 'bed linen changes', 'linen changes and', \"changes and 'Do\", \"and 'Do not\", \"'Do not disturb\", \"not disturb '\", \"disturb ' signs\", \"' signs left\", 'signs left on', 'left on room', 'on room doors', 'room doors for', 'doors for days', 'for days .', 'days . A', '. A mobile', 'A mobile phone', 'mobile phone app', 'phone app called', 'app called Rescue', 'called Rescue Me', 'Rescue Me ,', 'Me , which', ', which will', 'which will allow', 'will allow staff', 'allow staff to', 'staff to alert', 'to alert police', 'alert police of', 'police of suspicious', 'of suspicious behaviour', 'suspicious behaviour ,', 'behaviour , will', ', will be', 'will be developed', 'be developed .', 'developed . The', '. The initiative', 'The initiative has', 'initiative has been', 'has been backed', 'been backed by', 'backed by the', 'by the Maharashtra', 'the Maharashtra government', 'Maharashtra government .']\n",
            "4-gramas:  ['Hotels in Maharashtra will', 'in Maharashtra will train', 'Maharashtra will train their', 'will train their staff', 'train their staff to', 'their staff to spot', 'staff to spot signs', 'to spot signs of', 'spot signs of sex', 'signs of sex trafficking', 'of sex trafficking ,', 'sex trafficking , including', 'trafficking , including frequent', ', including frequent requests', 'including frequent requests for', 'frequent requests for bed', 'requests for bed linen', 'for bed linen changes', 'bed linen changes and', \"linen changes and 'Do\", \"changes and 'Do not\", \"and 'Do not disturb\", \"'Do not disturb '\", \"not disturb ' signs\", \"disturb ' signs left\", \"' signs left on\", 'signs left on room', 'left on room doors', 'on room doors for', 'room doors for days', 'doors for days .', 'for days . A', 'days . A mobile', '. A mobile phone', 'A mobile phone app', 'mobile phone app called', 'phone app called Rescue', 'app called Rescue Me', 'called Rescue Me ,', 'Rescue Me , which', 'Me , which will', ', which will allow', 'which will allow staff', 'will allow staff to', 'allow staff to alert', 'staff to alert police', 'to alert police of', 'alert police of suspicious', 'police of suspicious behaviour', 'of suspicious behaviour ,', 'suspicious behaviour , will', 'behaviour , will be', ', will be developed', 'will be developed .', 'be developed . The', 'developed . The initiative', '. The initiative has', 'The initiative has been', 'initiative has been backed', 'has been backed by', 'been backed by the', 'backed by the Maharashtra', 'by the Maharashtra government', 'the Maharashtra government .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQtljYo-mcRi"
      },
      "source": [
        "***Spacy***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEzzKOSKs5qT"
      },
      "source": [
        "Spacy no tiene actualmente integrado esta funcionalidad, así que utilizaremos una librería auxiliar que funciona con sus clases, llamada textacy.\n",
        "\n",
        "Primero, importamos las librerías, el modelo en inglés y como antes, procesamos con el modelo los documentos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPCkHZswqCCw"
      },
      "source": [
        "import spacy\n",
        "import textacy\n",
        "\n",
        "# Cargamos el modelo preentrenado con textos en inglés\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "# Creamos un objeto spacy nlp con los textos para que sea preprocesado con el modelo anterior\n",
        "nlp_texto = [nlp(texto_to_process) for texto_to_process in subset_noticias]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzYvbIaJqJNO"
      },
      "source": [
        "Utilizaremos la librería textacy para extraer esta información:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WHlU1oimcRi",
        "outputId": "f5d44238-84ff-4c20-81a0-08343230ff26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " # Calculamos los bigramas, trigramas y 4 gramas de la noticia 4\n",
        "print(\"Bigramas: \", list(textacy.extract.ngrams(nlp_texto[4],2, min_freq=1, filter_stops = False, filter_punct =False)))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigramas:  [Hotels in, in Maharashtra, Maharashtra will, will train, train their, their staff, staff to, to spot, spot signs, signs of, of sex, sex trafficking, trafficking,, , including, including frequent, frequent requests, requests for, for bed, bed linen, linen changes, changes and, and ', 'Do, Do not, not disturb, disturb', ' signs, signs left, left on, on room, room doors, doors for, for days, days., . A, A mobile, mobile phone, phone app, app called, called Rescue, Rescue Me, Me,, , which, which will, will allow, allow staff, staff to, to alert, alert police, police of, of suspicious, suspicious behaviour, behaviour,, , will, will be, be developed, developed., . The, The initiative, initiative has, has been, been backed, backed by, by the, the Maharashtra, Maharashtra government, government.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trigramas: \", list(textacy.extract.ngrams(nlp_texto[4],3, min_freq=1, filter_stops = False, filter_punct =False)))\n",
        "print(\"4-gramas: \", list(textacy.extract.ngrams(nlp_texto[4],4, min_freq=1, filter_stops = False, filter_punct =False)))\n",
        "\n"
      ],
      "metadata": {
        "id": "iDtRYPdsgoWu",
        "outputId": "9e1135eb-9ec1-428f-b0d9-18f590e1ac46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigramas:  [Hotels in Maharashtra, in Maharashtra will, Maharashtra will train, will train their, train their staff, their staff to, staff to spot, to spot signs, spot signs of, signs of sex, of sex trafficking, sex trafficking,, trafficking, including, , including frequent, including frequent requests, frequent requests for, requests for bed, for bed linen, bed linen changes, linen changes and, changes and ', and 'Do, 'Do not, Do not disturb, not disturb', disturb' signs, ' signs left, signs left on, left on room, on room doors, room doors for, doors for days, for days., days. A, . A mobile, A mobile phone, mobile phone app, phone app called, app called Rescue, called Rescue Me, Rescue Me,, Me, which, , which will, which will allow, will allow staff, allow staff to, staff to alert, to alert police, alert police of, police of suspicious, of suspicious behaviour, suspicious behaviour,, behaviour, will, , will be, will be developed, be developed., developed. The, . The initiative, The initiative has, initiative has been, has been backed, been backed by, backed by the, by the Maharashtra, the Maharashtra government, Maharashtra government.]\n",
            "4-gramas:  [Hotels in Maharashtra will, in Maharashtra will train, Maharashtra will train their, will train their staff, train their staff to, their staff to spot, staff to spot signs, to spot signs of, spot signs of sex, signs of sex trafficking, of sex trafficking,, sex trafficking, including, trafficking, including frequent, , including frequent requests, including frequent requests for, frequent requests for bed, requests for bed linen, for bed linen changes, bed linen changes and, linen changes and ', changes and 'Do, and 'Do not, 'Do not disturb, Do not disturb', not disturb' signs, disturb' signs left, ' signs left on, signs left on room, left on room doors, on room doors for, room doors for days, doors for days., for days. A, days. A mobile, . A mobile phone, A mobile phone app, mobile phone app called, phone app called Rescue, app called Rescue Me, called Rescue Me,, Rescue Me, which, Me, which will, , which will allow, which will allow staff, will allow staff to, allow staff to alert, staff to alert police, to alert police of, alert police of suspicious, police of suspicious behaviour, of suspicious behaviour,, suspicious behaviour, will, behaviour, will be, , will be developed, will be developed., be developed. The, developed. The initiative, . The initiative has, The initiative has been, initiative has been backed, has been backed by, been backed by the, backed by the Maharashtra, by the Maharashtra government, the Maharashtra government.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdVM3n4jqTeA"
      },
      "source": [
        "\n",
        "**Visualización:**\n",
        "\n",
        "A continuación, vamos a calcular los tokens y bigramas de todo el corpus de documentos y vamos a generar una visualización.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2_Se24-qh43"
      },
      "source": [
        "def frecuencia_tokens(lista): \n",
        "    # Creamos diccionario vacío \n",
        "    frecuencia = {} \n",
        "    for item in lista: \n",
        "        if (item in frecuencia): \n",
        "            frecuencia[item] += 1\n",
        "        else: \n",
        "            frecuencia[item] = 1\n",
        "    return frecuencia"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero extraemos los tokens de todos los textos y los introducimos en una lista común."
      ],
      "metadata": {
        "id": "IMNiNlvT485I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3mjXo0PsSRx"
      },
      "source": [
        "lista_tokens = list()\n",
        "for i in subset_noticias:\n",
        "  # Tokenizamos cada documento con word_tokenize()\n",
        "  tokens_document = word_tokenize(i)\n",
        "  # Añadimos esos tokens como nuevos elementos\n",
        "  # Si usamos append se crearía una lista de listas, de este modo añadimos los\n",
        "  lista_tokens.extend(tokens_document)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después calculamos la frecuencia con la función generada."
      ],
      "metadata": {
        "id": "yUENTulP5C5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Calculemos la frecuencia\n",
        "dict_freq = frecuencia_tokens(lista_tokens)\n",
        "dict_freq[\"Road\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwU16gOu4x6C",
        "outputId": "cad97c95-5c23-47f4-9c00-ce382349e0b2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.44 ms, sys: 4 µs, total: 2.44 ms\n",
            "Wall time: 2.47 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambien podemos utilizar un counter (más eficiente):"
      ],
      "metadata": {
        "id": "lU_kCKkw4iEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "Cl7HTptL5L9p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dict_freq2 = Counter(lista_tokens)\n",
        "dict_freq2[\"Road\"]"
      ],
      "metadata": {
        "id": "9lkbcvxx4hh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40174c56-c9e4-4fb5-9449-09f5426661e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.36 ms, sys: 982 µs, total: 3.34 ms\n",
            "Wall time: 3.39 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIWkLjav35k"
      },
      "source": [
        "Vamos a ordenar el diccionario, para tomar sólo los valores mayores de 20:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLACbxLtuTg0"
      },
      "source": [
        "# Ordenamos el diccionario por la frecuencia de sus palabras\n",
        "dict_freq_order = sorted(dict_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "token_names = list()\n",
        "token_freqs = list()\n",
        "for i in dict_freq_order:\n",
        "  if i[1] > 30:\n",
        "    token_names.append(i[0])\n",
        "    token_freqs.append(i[1])\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZDIKJsvuJ1n"
      },
      "source": [
        "Dibujemos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcncvfRuuLpF",
        "outputId": "12ed7c3d-7334-450c-80e4-7c09f59c1d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "sns_g = sns.barplot(x=token_names, y=token_freqs)\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19, 20, 21, 22, 23, 24]),\n",
              " <a list of 25 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN7lUnzDWKHV"
      },
      "source": [
        "Se podrían quitar los símbolos de puntuación y stopwords con:\n",
        "\n",
        "\n",
        "```\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "punctuations = string.punctuation\n",
        "stop_words = stopwords.words('english')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAGXKfq1Adq0"
      },
      "source": [
        "## Lematización y stemming\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDHENh2AjtC"
      },
      "source": [
        "Las lemas son las formas canónicas del léxico de un idioma. Por ejemplo, en el caso del español, los verbos presentan una flexión verbal, conocida como comúnmente como conjungación, utilizada para adaptar el verbo a diferentes situaciones de contexto (número, género y tiempo verbal) y presentando distinta forma escrita. En algunas ocasiones, es útil utilizar el lema de los verbos y otras palabras para reducir la dimensionalidad en los modelos predictivos. Este proceso es conocido como lematización. Cuando se lematiza se obtienen palabras reales ya que se utilizan diccionarios jerárquicos para obtener el lema. Este diccionario jerárquico es conocido como WordNet, y será explicado con profundidad más adelante.\n",
        "\n",
        "Un caso específico y simple de la lematización es el stemming, que consiste en utilizar reglas sintácticas para quitar la finalización de las palabras y reducirlas así una forma común llamada stem. Hay muchos stemmers populares como el de Porter o el de Snowball. **Es importante mencionar que no siempre que se hace stemming de una palabra esta es una palabra real, si no una palabra sin su última(s) letras**\n",
        "\n",
        "A continuación se muestran ests procesos tanto para NLTK como para Spacy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgcmTIhpknzw"
      },
      "source": [
        "***NLTK***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaoh0uTLkqqy"
      },
      "source": [
        "**Stemming**\n",
        "\n",
        "En NLTK hay varias implementaciones de algoritmos de Stemming. Aquí mostraremos los dos más utilizados: \n",
        "\n",
        "- Algoritmo de Porter Stemming: Algoritmo que solo funciona en inglés y que funciona correctamente con la mayoría de las palabras en ese idioma. Sirve para quitar sustituir los sufijos de las plabras.\n",
        "\n",
        "- Algoritmo de SnowballStemmer: Algoritmo de Stemming que soporta 13 lenguas en NLTK, incluyendo español. Es una versión mejorada del algoritmo de de Porter Stemming.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Ow8mTdEWT4"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "\n",
        "# In English\n",
        "list_of_english_words = [\"Speaking\",\"speaks\",\"Speaker\",\"dogs\",\"buses\", \"pieces\",'compute', 'computer', 'computed', 'computing']\n",
        "SStemmer = PorterStemmer()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-A9wfpCknzy",
        "outputId": "8c2ce761-cf00-4abb-ab9e-0582aa4d0a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "\n",
        "# In English\n",
        "list_of_english_words = [\"Speaking\",\"speaks\",\"Speaker\",\"dogs\",\"buses\", \"pieces\",'compute', 'computer', 'computed', 'computing']\n",
        "# Cargamos los Stemer\n",
        "SStemmer = PorterStemmer()\n",
        "PStemmer = SnowballStemmer(\"english\")\n",
        "print(\"Términos en inglés:\")\n",
        "for word in list_of_english_words:\n",
        "  print(\"Palabra original: {}, Porter Stemmer: {}, Snowball: {}\".format(word,PStemmer.stem(word),SStemmer.stem(word)))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Términos en inglés:\n",
            "Palabra original: Speaking, Porter Stemmer: speak, Snowball: speak\n",
            "Palabra original: speaks, Porter Stemmer: speak, Snowball: speak\n",
            "Palabra original: Speaker, Porter Stemmer: speaker, Snowball: speaker\n",
            "Palabra original: dogs, Porter Stemmer: dog, Snowball: dog\n",
            "Palabra original: buses, Porter Stemmer: buse, Snowball: buse\n",
            "Palabra original: pieces, Porter Stemmer: piec, Snowball: piec\n",
            "Palabra original: compute, Porter Stemmer: comput, Snowball: comput\n",
            "Palabra original: computer, Porter Stemmer: comput, Snowball: comput\n",
            "Palabra original: computed, Porter Stemmer: comput, Snowball: comput\n",
            "Palabra original: computing, Porter Stemmer: comput, Snowball: comput\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KleW4_rE2Mh",
        "outputId": "28177c60-47f3-4606-eb33-76178904ae28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#En español\n",
        "lista_de_palabras_espano = [\"Hablando\", \"Habla\", \"Hablador\", \"Hablará\", \"ha hablado\"]\n",
        "\n",
        "SStemmer_spanish = SnowballStemmer(\"spanish\")\n",
        "print(\"Términos en español:\")\n",
        "for word in lista_de_palabras_espano:\n",
        "  print(\"Palabra original: {}, Snowball: {}\".format(word, SStemmer_spanish.stem(word)))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Términos en español:\n",
            "Palabra original: Hablando, Snowball: habl\n",
            "Palabra original: Habla, Snowball: habl\n",
            "Palabra original: Hablador, Snowball: hablador\n",
            "Palabra original: Hablará, Snowball: habl\n",
            "Palabra original: ha hablado, Snowball: ha habl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPAjczcUts7e"
      },
      "source": [
        "**Lematización**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0o38bBrulAU"
      },
      "source": [
        "En español no se puede utilizar este método, dado que WordNet solo tiene términos en inglés. \n",
        "En este ejemplo vamos a lematizar palabras individuales, sin una categoría gramatical asignada. Si tuvieramos la PoS funcionaría con mejor rendimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6iSQMGwttQj",
        "outputId": "a2b3abd9-c667-45bf-e5e3-4fdb9b583bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lematizador = WordNetLemmatizer()\n",
        "list_of_english_words = [\"Speaking\",\"speaks\",\"Speaker\",\"dogs\",\"buses\", \"pieces\",'compute', \"computes\", 'computer', 'computed', 'computing']\n",
        "for word in list_of_english_words:\n",
        "  print(\" {} ---> {}\".format(word,lematizador.lemmatize(word)))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Speaking ---> Speaking\n",
            " speaks ---> speaks\n",
            " Speaker ---> Speaker\n",
            " dogs ---> dog\n",
            " buses ---> bus\n",
            " pieces ---> piece\n",
            " compute ---> compute\n",
            " computes ---> computes\n",
            " computer ---> computer\n",
            " computed ---> computed\n",
            " computing ---> computing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnfdMo_uvvB8"
      },
      "source": [
        "Notesé que, a diferencia del stemmer, las palabras en plural que no se forman solo con una s y que se producían errores, aquí lo hace sin problemas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a_wmd1Lknzz"
      },
      "source": [
        "***Spacy***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevlXnLVknz0"
      },
      "source": [
        "Debido al funcionamiento de Spacy, que funciona con modelos pre-entrenados de DeepLearning que incorporan distintas características, no existen funciones para hacer stemming y si para lematizar. Este proceso lo hace a partir de los conocimientos adquiridos en el proceso de entrenamiento del modelo con millones de textos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy9rVMwHknz1",
        "outputId": "e01db8d9-e571-4b46-b5c5-e7314b2524b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Cargamos el modelo preentrenado con textos en inglés\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "english_sentence = \"I bought five tickets on the internet, after a long wait 5 buses passed by, but none of them was the correct one\"\n",
        "\n",
        "word_sp = nlp(english_sentence)\n",
        "for word in word_sp:\n",
        "  print(word.text, \"---->\", word.lemma_)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I ----> I\n",
            "bought ----> buy\n",
            "five ----> five\n",
            "tickets ----> ticket\n",
            "on ----> on\n",
            "the ----> the\n",
            "internet ----> internet\n",
            ", ----> ,\n",
            "after ----> after\n",
            "a ----> a\n",
            "long ----> long\n",
            "wait ----> wait\n",
            "5 ----> 5\n",
            "buses ----> bus\n",
            "passed ----> pass\n",
            "by ----> by\n",
            ", ----> ,\n",
            "but ----> but\n",
            "none ----> none\n",
            "of ----> of\n",
            "them ----> they\n",
            "was ----> be\n",
            "the ----> the\n",
            "correct ----> correct\n",
            "one ----> one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X1hrzTrAkyG"
      },
      "source": [
        "## Part-Of-Speech Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23_6p5X35y_3"
      },
      "source": [
        "El *Part-Of-Speech Tagging* o la asignación de categorías gramaticales a una frase es el proceso en el que a una lista de palabras es etiquetada con su categoría gramatical, es decir que identifica si la palabra es un nombre, un adjetivo, un verbo, un adverbio, etc.\n",
        "\n",
        "La asignación de etiquetas gramaticales es interesante cuando se quiere hacer análisis gramatical de una oración, para saber si una palabra tiene una acepción u otra, o incluso para extraer características artificiales cuando se quiere hacer una clasificación textual o similar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFbmnQhc6k84"
      },
      "source": [
        "**NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-XvZm0-i4O"
      },
      "source": [
        "El listado de etiquetas de NLTK es el utilizado por UPenn (University of Pennsylvania). Para ver el listado completo solo hay que ejecutar la siguiente línea de código:\n",
        "\n",
        "\n",
        "```\n",
        "nltk.help.upenn_tagset()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlTZmPbrGxBB",
        "outputId": "3460d879-f884-47de-b83e-431d52983661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.help.upenn_tagset()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw191IO06kRr",
        "outputId": "70a399eb-8966-4b5f-8f5a-7dfff0565c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "\n",
        "\n",
        "# Segmentamos los tokens\n",
        "tokens = word_tokenize(subset_noticias[4])\n",
        "\n",
        "# Utilizamos la función pos_tag() de nltk para obtener las etiquetas\n",
        "pos_tag(tokens)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hotels', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('Maharashtra', 'NNP'),\n",
              " ('will', 'MD'),\n",
              " ('train', 'VB'),\n",
              " ('their', 'PRP$'),\n",
              " ('staff', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('spot', 'VB'),\n",
              " ('signs', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('sex', 'NN'),\n",
              " ('trafficking', 'NN'),\n",
              " (',', ','),\n",
              " ('including', 'VBG'),\n",
              " ('frequent', 'JJ'),\n",
              " ('requests', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('bed', 'NN'),\n",
              " ('linen', 'NN'),\n",
              " ('changes', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " (\"'Do\", 'MD'),\n",
              " ('not', 'RB'),\n",
              " ('disturb', 'VB'),\n",
              " (\"'\", \"''\"),\n",
              " ('signs', 'NNS'),\n",
              " ('left', 'VBD'),\n",
              " ('on', 'IN'),\n",
              " ('room', 'NN'),\n",
              " ('doors', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('days', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('mobile', 'JJ'),\n",
              " ('phone', 'NN'),\n",
              " ('app', 'NN'),\n",
              " ('called', 'VBN'),\n",
              " ('Rescue', 'NNP'),\n",
              " ('Me', 'NNP'),\n",
              " (',', ','),\n",
              " ('which', 'WDT'),\n",
              " ('will', 'MD'),\n",
              " ('allow', 'VB'),\n",
              " ('staff', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('alert', 'VB'),\n",
              " ('police', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('suspicious', 'JJ'),\n",
              " ('behaviour', 'NN'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('developed', 'VBN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('initiative', 'NN'),\n",
              " ('has', 'VBZ'),\n",
              " ('been', 'VBN'),\n",
              " ('backed', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Maharashtra', 'NNP'),\n",
              " ('government', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkxS8J_q7UG8"
      },
      "source": [
        "**Spacy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8k58QvD_q1Y"
      },
      "source": [
        "El listado de etiquetas POS utilizadas en Spacy es el siguiente:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "SPACY_POS_LIST = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\",\n",
        "                  \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \n",
        "                  \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\", \"SPACE\"]\n",
        "```\n",
        "\n",
        "Si se necesita recordar que significa una de las abreviaciones se puede utilizar el código:\n",
        "\n",
        "```\n",
        "spacy.explain(\"NN\")\n",
        "# 'noun, singular or mass'\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n9q07Fg9Hng8",
        "outputId": "85a78cad-dd70-4b89-9093-7074283d4b7d"
      },
      "source": [
        "spacy.explain(\"NP\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noun phrase'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syle9jPL5zMy",
        "outputId": "f8fcf049-07c0-4227-d704-ade3da0405e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "\n",
        "\n",
        "# Segmentamos los tokens\n",
        "tokens = nlp(subset_noticias[4])\n",
        "for w in tokens:\n",
        "    print( \"The word '{}' is a {} \".format(w.text, w.pos_))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'Hotels' is a NOUN \n",
            "The word 'in' is a ADP \n",
            "The word 'Maharashtra' is a PROPN \n",
            "The word 'will' is a AUX \n",
            "The word 'train' is a VERB \n",
            "The word 'their' is a PRON \n",
            "The word 'staff' is a NOUN \n",
            "The word 'to' is a PART \n",
            "The word 'spot' is a VERB \n",
            "The word 'signs' is a NOUN \n",
            "The word 'of' is a ADP \n",
            "The word 'sex' is a NOUN \n",
            "The word 'trafficking' is a NOUN \n",
            "The word ',' is a PUNCT \n",
            "The word 'including' is a VERB \n",
            "The word 'frequent' is a ADJ \n",
            "The word 'requests' is a NOUN \n",
            "The word 'for' is a ADP \n",
            "The word 'bed' is a NOUN \n",
            "The word 'linen' is a NOUN \n",
            "The word 'changes' is a NOUN \n",
            "The word 'and' is a CCONJ \n",
            "The word ''' is a PUNCT \n",
            "The word 'Do' is a AUX \n",
            "The word 'not' is a PART \n",
            "The word 'disturb' is a VERB \n",
            "The word ''' is a PUNCT \n",
            "The word 'signs' is a NOUN \n",
            "The word 'left' is a VERB \n",
            "The word 'on' is a ADP \n",
            "The word 'room' is a NOUN \n",
            "The word 'doors' is a NOUN \n",
            "The word 'for' is a ADP \n",
            "The word 'days' is a NOUN \n",
            "The word '.' is a PUNCT \n",
            "The word 'A' is a DET \n",
            "The word 'mobile' is a ADJ \n",
            "The word 'phone' is a NOUN \n",
            "The word 'app' is a NOUN \n",
            "The word 'called' is a VERB \n",
            "The word 'Rescue' is a PROPN \n",
            "The word 'Me' is a PRON \n",
            "The word ',' is a PUNCT \n",
            "The word 'which' is a PRON \n",
            "The word 'will' is a AUX \n",
            "The word 'allow' is a VERB \n",
            "The word 'staff' is a NOUN \n",
            "The word 'to' is a PART \n",
            "The word 'alert' is a VERB \n",
            "The word 'police' is a NOUN \n",
            "The word 'of' is a ADP \n",
            "The word 'suspicious' is a ADJ \n",
            "The word 'behaviour' is a NOUN \n",
            "The word ',' is a PUNCT \n",
            "The word 'will' is a AUX \n",
            "The word 'be' is a AUX \n",
            "The word 'developed' is a VERB \n",
            "The word '.' is a PUNCT \n",
            "The word 'The' is a DET \n",
            "The word 'initiative' is a NOUN \n",
            "The word 'has' is a AUX \n",
            "The word 'been' is a AUX \n",
            "The word 'backed' is a VERB \n",
            "The word 'by' is a ADP \n",
            "The word 'the' is a DET \n",
            "The word 'Maharashtra' is a PROPN \n",
            "The word 'government' is a NOUN \n",
            "The word '.' is a PUNCT \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu1-q-c15zeo"
      },
      "source": [
        "## Named-entiy recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvPUPLeBD1BB"
      },
      "source": [
        "La extración de entidades de un documento es una labor esencial en la análitica de textos. En algunas ocasiones puede ser interesante si se nombra a una persona, a una ciudad, un país o incluso a un medicamento, en el caso de los textos clínicos. \n",
        "\n",
        "Existen sistemas NER (Named-entity recognition) específicos para cada campo de aplicación. Las librerías de NLTK y Spacy disponen de modelos para detectar entidades de ámbito general, aunque existen modelos mucho más espcificos para reconocer entidades muy específicos como por ejemplo síntomas en textos clinicos (mención a BSC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfR0qjpoWmej"
      },
      "source": [
        "**NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6mFV-cYt1G"
      },
      "source": [
        "En NLTK antes de detectar es necesario la obtención de la tokenización y la POS tag antes de identificar entidades, ya que utiliza las etiquetas POS y reglas internas para encontrar que elementos son personas u otro tipo de entidad. \n",
        "\n",
        "Cuando los textos son extraidos de internet, hay que quitar los espacios extras que puede haber en una frase, para que se extraiga mejor las categorías gramaticales de éstos y poder así reconocer mejor las organizaciones o personas en el texto. En este caso están bastante limpios, así que no hace falta hacerlo. \n",
        "\n",
        "Importamos la función `ne_chunk`, que necesita un conjunto de tokens etiquetados PoS previamente. Así que antes hay que preprocesar el documento. Lo haremos con la función `preprocesar()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGyfI1rIrsZ"
      },
      "source": [
        "from nltk.chunk import ne_chunk\n",
        "?ne_chunk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_p-ADJ22GuZ"
      },
      "source": [
        "from nltk.chunk import ne_chunk\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "\n",
        "def preprocess(documento):\n",
        "  # word_tokenizer\n",
        "  documento_tok = ________________\n",
        "  # pos_tag\n",
        "  documento_pos = ________________\n",
        "  return documento_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFkityaA3aOC"
      },
      "source": [
        "Ejecutemos la función sobre la noticia 4 y extraigamos las named-entities:\n",
        "\n",
        "Primero preprocesamos, que vemos que nos devuelve una lista de tuplas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYwXjzOCKo93"
      },
      "source": [
        "noticia = _______________________\n",
        "noticia[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos esa salida para observar la presencia de entidades nombradas:"
      ],
      "metadata": {
        "id": "AMSKQ47f5ugG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY6W9toAWmt0"
      },
      "source": [
        "ne_tree = ___________________\n",
        "print(ne_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVr2luKWnIN"
      },
      "source": [
        "**Spacy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpihd1A3qHJ"
      },
      "source": [
        "En Spacy es mucho más sencillo. Cuando procesamos un documento con el modelo importado, automáticamente se le aplica un conjunto de instrucciones internamente para detectar tokens, lemas... y también las entidades nombradas, a las que se puede acceder iterando sobre el atributo `ents` y extrayendo la etiqueta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDsyKsi14bCZ"
      },
      "source": [
        "# Cogemos un subset de las noticias para acelerar el proceso:\n",
        "subset_noticias = texto_noticias[0:100]\n",
        "\n",
        "# Segmentamos los tokens\n",
        "tokens = nlp(\"John was born in Chicken, Alaska, and studies at Cranberry Lemon University. John likes to go to Starbucks.\")\n",
        "print([(X.text, X.label_) for X in tokens.ents])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v4QB7Le4cV8"
      },
      "source": [
        "Además, spacy incorpora un módulo para visualizar estas entidades en un gráfico. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2T6yJ6q5z4j"
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(tokens, jupyter=True, style='ent')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYIyf8SJ50J7"
      },
      "source": [
        "## Estructura de la frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBPA59QO5_sR"
      },
      "source": [
        "from spacy import displacy\n",
        "tokens = nlp(\"John was born in Chicken, Alaska, and studies at Cranberry Lemon University. John likes to go to Starbucks.\")\n",
        "displacy.render(tokens,style='dep',jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT_WjLJf6ADK"
      },
      "source": [
        "## WordNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv1HytrW4nhN"
      },
      "source": [
        "WordNet 3.0 es un diccionario jerárquico desarrollado por la Universidad de Princeton, que categoría las acepciones de todas las palabras del inglés en relaciones semánticas con otras.\n",
        "\n",
        "Se puede acceder fácilmente a Wordnet utilizando NLTK mediante la función wordnet del módulo corpus.\n",
        "\n",
        "Por ejemplo, busquemos la palabra \"bank\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ3KVFi06ANu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957dc38b-6e16-4f4b-8ff5-24f3f42628c7"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "syn = wordnet.synsets(\"bank\")\n",
        "print(syn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10'), Synset('bank.v.01'), Synset('bank.v.02'), Synset('bank.v.03'), Synset('bank.v.04'), Synset('bank.v.05'), Synset('deposit.v.02'), Synset('bank.v.07'), Synset('trust.v.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTe7cVF25CTX"
      },
      "source": [
        "Al mostrar los synsets de esa palbra se observa que hay varios que contienen la palabra bank. \n",
        "Vamos a mostrar la definición y ejemplos de uso de alguno de ellos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6LwXk9v5W5e"
      },
      "source": [
        "print(\"bank.n.01 definition: \" + syn[0].definition())\n",
        "print(syn[0].examples())\n",
        "\n",
        "print(\"bank.n.04 definition: \" + syn[5].definition())\n",
        "print(syn[5].examples())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9tSxzFK6kOU"
      },
      "source": [
        "Se pueden buscar la distancia exitente entre los synsets para intentar comprender su similitud semántica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PassGgcXeC70"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "dog = wordnet.synset('dog.n.01')\n",
        "cat = wordnet.synset('cat.n.01')\n",
        "fox = wordnet.synset('fox.n.01')\n",
        "\n",
        "print(\"path similarity between dog and cat: \",dog.path_similarity(cat))\n",
        "print(\"path similarity between dog and fox: \",dog.path_similarity(fox))\n",
        "print(\"path similarity between cat and fox: \",cat.path_similarity(fox))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGQMv38J7w0l"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Es interesante saber cargar embeddings pre-entrenados. En la clase de mañana utilizaremos embeddings para ayudar a sistemas de análisis de sentimiento, así que vamos a aprender a cargarlos hoy. [LINK](https://nlp.stanford.edu/projects/glove/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZX9fJWT72gm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f639bce7-fd50-4ed0-8d31-6ff036d3b02f"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# Unzip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-12 18:06:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-03-12 18:06:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-03-12 18:06:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.20MB/s    in 2m 45s  \n",
            "\n",
            "2021-03-12 18:09:21 (4.97 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAeFNs0oPnjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5faa16-1424-432f-ec4a-924617d94763"
      },
      "source": [
        "!unzip glove.6B.zip\n",
        "# Get the path of the zip\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGcUFlTx-nP2"
      },
      "source": [
        "# Librerías tpipicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def cargaGlove(gloveFile):\n",
        "    print(\"Cargando modelo Glove\")\n",
        "    f = open(gloveFile,'r')\n",
        "    modelo = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        modelo[word] = embedding\n",
        "    print(\"Finalizado.\",len(modelo),\" palabras\")\n",
        "    return modelo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96LebTjf9rQV"
      },
      "source": [
        "glove_model = cargaGlove(\"/content/glove.6B.100d_1.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X4pEoBJA3HB"
      },
      "source": [
        "rana = glove_model[\"frog\"]\n",
        "print(rana)\n",
        "lagarto = glove_model[\"lizard\"]\n",
        "perro = glove_model[\"dog\"]\n",
        "libro = glove_model[\"book\"]\n",
        "humano = glove_model[\"person\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTNwodPTBEkZ"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(cosine_similarity([rana],[lagarto]))\n",
        "print(cosine_similarity([rana],[perro]))\n",
        "print(cosine_similarity([rana],[libro]))\n",
        "print(cosine_similarity([humano],[perro]))\n",
        "print(cosine_similarity([humano],[rana]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa80h6Vk_gYE"
      },
      "source": [
        "print(glove_model[\"sad\"])\n",
        "print(glove_model[\"happy\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}